{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b06877-ac3c-416f-8822-5b25c2b46d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import argparse\n",
    "import scipy.stats\n",
    "import scipy.special as special\n",
    "from typing import Dict, List, Any, Tuple\n",
    "\n",
    "from subset_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7c76e7-36f3-4ff4-bcd6-5a785f81b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aad3f7-cdec-4b71-b51c-559d25bc79a7",
   "metadata": {},
   "source": [
    "### Randomly sample examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4f247-8ca7-4bd4-8c60-797412bb97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = [\"42/cogs\"]\n",
    "METRICS = [\"Inverse PPL\", \"CHIA\", \"BLEU\"]\n",
    "CRITERIA = [\"Easy to Learn\", \"Ambiguous\", \"Hard to Learn\"]\n",
    "CONVERGE_EPOCHS = [10, 20]\n",
    "RATIO = 0.05\n",
    "\n",
    "for DATASET_NAME, CONVERGE_EPOCH in zip(DATASET_NAMES, CONVERGE_EPOCHS):\n",
    "    OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "    idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "    df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "    for METRIC in METRICS:\n",
    "        for CRITERION in CRITERIA:\n",
    "            print(DATASET_NAME.split(\"/\")[-1], METRIC, CRITERION, \"\\n\")\n",
    "            idx_fname = create_ratio_fname(METRIC, CRITERION, CONVERGE_EPOCH, RATIO)\n",
    "            subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, ratio=RATIO, write=False)\n",
    "            samples = subset_df.sample(1, replace=False)\n",
    "            for idx in range(len(samples)):\n",
    "                sample = samples.iloc[idx]\n",
    "                print(sample[7])\n",
    "                print(sample[8], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d02e79-4630-4f14-9b4a-24cd2635b438",
   "metadata": {},
   "source": [
    "### Calculate subset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0a662-4972-40a8-881e-6deea061a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES_LIST = [[\"0/cogs\", \"42/cogs\", \"123/cogs\"], [\"0/cfq\", \"42/cfq\", \"123/cfq\"]]\n",
    "METRICS = [\"Inverse PPL\", \"CHIA\", \"BLEU\"]\n",
    "CRITERIA = [\"Easy to Learn\", \"Ambiguous\", \"Hard to Learn\", \"Random\"]\n",
    "CONVERGE_EPOCHS = [10, 20]\n",
    "RATIO = 0.33\n",
    "\n",
    "for DATASET_NAMES, CONVERGE_EPOCH in zip(DATASET_NAMES_LIST, CONVERGE_EPOCHS):\n",
    "    for METRIC in METRICS:\n",
    "        for CRITERION in CRITERIA:\n",
    "            DESCRIBE_SUM = None\n",
    "            for DATASET_NAME in DATASET_NAMES:\n",
    "                OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "                idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "                df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "                idx_fname = create_ratio_fname(METRIC, CRITERION, CONVERGE_EPOCH, RATIO)\n",
    "                subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, ratio=RATIO)\n",
    "                if DESCRIBE_SUM is None:\n",
    "                    DESCRIBE_SUM = subset_df.describe()\n",
    "                else:\n",
    "                    DESCRIBE_SUM += subset_df.describe()\n",
    "            DESCRIBE_SUM /= len(DATASET_NAMES)\n",
    "            print(DATASET_NAME.split(\"/\")[-1], METRIC, CRITERION)\n",
    "            print(\"Length\", f'{DESCRIBE_SUM[\"In Len\"][1]:.2f} / {DESCRIBE_SUM[\"Out Len\"][1]:.2f}')\n",
    "            print(\"Rarity\", f'{DESCRIBE_SUM[\"In Rarity\"][1]:.2f} / {DESCRIBE_SUM[\"Out Rarity\"][1]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a2eab-ecd5-4705-96cb-3be890e16e83",
   "metadata": {},
   "source": [
    "### Read subset lengths for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8410e2-a388-4ffa-be23-3b6cb96ff8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = [\"0/cogs\", \"0/cfq\"]\n",
    "METRICS = [\"Inverse PPL\", \"CHIA\", \"BLEU\"]\n",
    "CRITERIA = [\"Easy to Learn\", \"Ambiguous\", \"Hard to Learn\", \"Random\"]\n",
    "CONVERGE_EPOCHS = [10, 20]\n",
    "RATIOS = [0.33]\n",
    "\n",
    "for DATASET_NAME, CONVERGE_EPOCH in zip(DATASET_NAMES, CONVERGE_EPOCHS):\n",
    "    OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "    for METRIC in METRICS:\n",
    "        for CRITERION in CRITERIA:\n",
    "            for RATIO in RATIOS:\n",
    "                idx_fname = create_ratio_fname(METRIC, CRITERION, CONVERGE_EPOCH, RATIO)\n",
    "                subset_df = read_pickle(\"subsets/\" + DATASET_NAME + \"/\" + idx_fname)\n",
    "                print(len(subset_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d10a8-3904-4f06-9ce8-a5f01615bfcd",
   "metadata": {},
   "source": [
    "### Combine subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fb5ff-7bef-4f6b-aa8b-8e867da6b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"cogs\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "\n",
    "METRICS = [\"Inverse PPL\"]#, \"CHIA\"]\n",
    "CRITERIA = [\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"] #, \"Ambiguous\",  \"Random\"]\n",
    "COMBINED_CRITERIA = list(itertools.combinations([\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"], 2))\n",
    "RATIOS = [0.5]\n",
    "CONVERGE_EPOCHS = [10]\n",
    "\n",
    "for RATIO in RATIOS:\n",
    "    for CONVERGE_EPOCH in CONVERGE_EPOCHS:\n",
    "        idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "        df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "        for METRIC in METRICS:\n",
    "            merge_dfs = []\n",
    "            for CRITERION in CRITERIA:\n",
    "                idx_fname = create_ratio_fname(METRIC, CRITERION, CONVERGE_EPOCH, RATIO)\n",
    "                subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, ratio=RATIO)\n",
    "                merge_df = pd.merge(df, subset_df, on=[\"Index\", \"In\", \"Out\", \"In abbv.\", \"Out abbv.\", \"In Len\", \"Out Len\", \"In Rarity\", \"Out Rarity\", \\\n",
    "                                                       'Confidence - Inverse PPL', 'Variability - Inverse PPL', \\\n",
    "                                                        'Confidence - CHIA', 'Variability - CHIA', \\\n",
    "                                                        'Confidence - BLEU', 'Variability - BLEU'], indicator=f\"merge_{crit2abv[CRITERION]}\", how='outer')\n",
    "                merge_dfs.append(merge_df)\n",
    "\n",
    "            merge_df = merge_dfs[0]\n",
    "            for i in range(1, len(merge_dfs)):\n",
    "                merge_df = pd.merge(merge_df, merge_dfs[i], on=[\"Index\", \"In\", \"Out\", \"In abbv.\", \"Out abbv.\", \"In Len\", \"Out Len\", \"In Rarity\", \"Out Rarity\", \\\n",
    "                                                        'Confidence - Inverse PPL', 'Variability - Inverse PPL', \\\n",
    "                                                        'Confidence - CHIA', 'Variability - CHIA', \\\n",
    "                                                        'Confidence - BLEU', 'Variability - BLEU'], how='outer')\n",
    "                print(merge_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91df2e-2ecb-4d10-a9da-d12b559badf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"cfq\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "\n",
    "METRICS = [\"Inverse PPL\"]#, \"CHIA\"]\n",
    "CRITERIA = [\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"] #, \"Ambiguous\",  \"Random\"]\n",
    "COMBINED_CRITERIA = list(itertools.combinations([\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"], 2))\n",
    "RATIOS = [0.33, 0.5]\n",
    "CONVERGE_EPOCHS = [20]\n",
    "\n",
    "for RATIO in RATIOS:\n",
    "    for CONVERGE_EPOCH in CONVERGE_EPOCHS:\n",
    "        idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "        df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "        for METRIC in METRICS:\n",
    "            merge_dfs = []\n",
    "            for CRITERION in CRITERIA:\n",
    "                idx_fname = create_ratio_fname(METRIC, CRITERION, CONVERGE_EPOCH, RATIO)\n",
    "                subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, ratio=RATIO)\n",
    "                merge_df = pd.merge(df, subset_df, on=[\"Index\", \"In\", \"Out\", \"In abbv.\", \"Out abbv.\", \"In Len\", \"Out Len\", \"In Rarity\", \"Out Rarity\", \\\n",
    "                                                       'Confidence - Inverse PPL', 'Variability - Inverse PPL', \\\n",
    "                                                        'Confidence - CHIA', 'Variability - CHIA', \\\n",
    "                                                        'Confidence - BLEU', 'Variability - BLEU'], indicator=f\"merge_{crit2abv[CRITERION]}\", how='outer')\n",
    "                merge_dfs.append(merge_df)\n",
    "\n",
    "            merge_df = merge_dfs[0]\n",
    "            for i in range(1, len(merge_dfs)):\n",
    "                merge_df = pd.merge(merge_df, merge_dfs[i], on=[\"Index\", \"In\", \"Out\", \"In abbv.\", \"Out abbv.\", \"In Len\", \"Out Len\", \"In Rarity\", \"Out Rarity\", \\\n",
    "                                                        'Confidence - Inverse PPL', 'Variability - Inverse PPL', \\\n",
    "                                                        'Confidence - CHIA', 'Variability - CHIA', \\\n",
    "                                                        'Confidence - BLEU', 'Variability - BLEU'], how='outer')\n",
    "                print(merge_df.columns)\n",
    "\n",
    "            merge_df[\"combined\"] = merge_df[\"merge_ambiguous\"].astype(str) + merge_df[\"merge_easy_to_learn\"].astype(str) + merge_df[\"merge_hard_to_learn\"].astype(str)\n",
    "            plot(merge_df, plot_type=\"inv_ppl\", color_column=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78eecfc-ee35-49bd-9694-12fd04eb64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"cfq\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRICS = [\"BLEU\", \"Inverse PPL\", \"CHIA\"]\n",
    "CRITERIA = [\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\", \"Random\"]\n",
    "RATIOS = [0.5]\n",
    "CONVERGE_EPOCHS = [20]\n",
    "\n",
    "for RATIO in RATIOS:\n",
    "    for CONVERGE_EPOCH in CONVERGE_EPOCHS:\n",
    "        idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE, min_epoch=3)\n",
    "        df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "        for METRIC in METRICS:\n",
    "            for CRITERION in CRITERIA:\n",
    "                idx_fname = create_ratio_fname(METRIC, CRITERION, CONVERGE_EPOCH, RATIO)\n",
    "                subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, ratio=RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6b209-293d-450f-9ad1-3cfacef2afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df[\"combined\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeddcebe-c42a-478a-8a46-01403d42d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"42/cogs\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "\n",
    "METRICS = [\"Inverse PPL\", \"CHIA\", \"BLEU\"]\n",
    "CRITERIA = [\"Hard to Learn\", \"Easy to Learn\", \"Ambiguous\"]\n",
    "COMBINED_CRITERIA = list(itertools.combinations([\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"], 2))\n",
    "CONVERGE_EPOCH = 10\n",
    "\n",
    "for METRIC in METRICS:\n",
    "    for CRITERIA in COMBINED_CRITERIA:\n",
    "        subset_dfs = []\n",
    "        for CRITERION in CRITERIA:\n",
    "            idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "            df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "            idx_fname = create_fname(METRIC, CRITERION, CONVERGE_EPOCH)\n",
    "            subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, write=False)\n",
    "            subset_dfs.append(subset_df)\n",
    "        idx_fname = create_comb_fname(METRIC, CRITERIA[0], CRITERIA[1], CONVERGE_EPOCH)\n",
    "        combined_set_df = combine_subsets(df, subset_dfs, DATASET_NAME, idx_fname)\n",
    "        \n",
    "        print(len(combined_set_df) / len(df))\n",
    "        desc_df = subset_df.describe()\n",
    "        #print(METRIC, CRITERION, f'In Len Mean: {desc_df[\"In Len\"][1]}', f'Out Len Mean: {desc_df[\"Out Len\"][1]}', f'In Rar Mean: {desc_df[\"In Rarity\"][1]}', f'Out Rar Mean: {desc_df[\"Out Rarity\"][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdb2b80-aad7-4385-8967-13308bc0196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_ppl_hard_to_learn_ambiguous_10.pickle 12078\n",
      "inv_ppl_hard_to_learn_easy_to_learn_10.pickle 12077\n",
      "inv_ppl_ambiguous_easy_to_learn_10.pickle 12077\n",
      "chia_hard_to_learn_ambiguous_10.pickle 12078\n",
      "chia_hard_to_learn_easy_to_learn_10.pickle 12077\n",
      "chia_ambiguous_easy_to_learn_10.pickle 12077\n",
      "bleu_hard_to_learn_ambiguous_10.pickle 12078\n",
      "bleu_hard_to_learn_easy_to_learn_10.pickle 12077\n",
      "bleu_ambiguous_easy_to_learn_10.pickle 12077\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"42/cogs\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "\n",
    "METRICS = [\"Inverse PPL\", \"CHIA\", \"BLEU\"]\n",
    "CRITERIA = [\"Hard to Learn\", \"Easy to Learn\", \"Ambiguous\"]\n",
    "COMBINED_CRITERIA = list(itertools.combinations([\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"], 2))\n",
    "CONVERGE_EPOCH = 10\n",
    "\n",
    "for METRIC in METRICS:\n",
    "    for CRITERIA in COMBINED_CRITERIA:\n",
    "            idx_fname = create_comb_fname(METRIC, CRITERIA[0], CRITERIA[1], CONVERGE_EPOCH)\n",
    "            print(idx_fname, len(list(read_pickle(os.path.join(\"subsets\", DATASET_NAME, idx_fname)))))\n",
    "\n",
    "\n",
    "# for METRIC in METRICS:\n",
    "#    for CRITERION in CRITERIA:\n",
    "#        for RATIO in RATIOS:\n",
    "#            idx_fname = create_ratio_fname(METRIC, CRITERION, CONVERGE_EPOCH, RATIO)\n",
    "#            print(idx_fname, len(list(read_pickle(os.path.join(\"subsets\", DATASET_NAME, idx_fname)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e52321-9500-4891-b3f0-6e79d108a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"42/cfq\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "\n",
    "METRICS = [\"Inverse PPL\", \"CHIA\", \"BLEU\"]\n",
    "CRITERIA = [\"Hard to Learn\", \"Easy to Learn\", \"Ambiguous\"]\n",
    "COMBINED_CRITERIA = list(itertools.combinations([\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"], 2))\n",
    "CONVERGE_EPOCH = 20\n",
    "\n",
    "for METRIC in METRICS:\n",
    "    for CRITERIA in COMBINED_CRITERIA:\n",
    "        subset_dfs = []\n",
    "        for CRITERION in CRITERIA:\n",
    "            idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "            df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "            idx_fname = create_fname(METRIC, CRITERION, CONVERGE_EPOCH)\n",
    "            subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, write=False)\n",
    "            subset_dfs.append(subset_df)\n",
    "        idx_fname = create_comb_fname(METRIC, CRITERIA[0], CRITERIA[1], CONVERGE_EPOCH)\n",
    "        combined_set_df = combine_subsets(df, subset_dfs, DATASET_NAME, idx_fname)\n",
    "        \n",
    "        print(len(combined_set_df) / len(df))\n",
    "        desc_df = subset_df.describe()\n",
    "        #print(METRIC, CRITERION, f'In Len Mean: {desc_df[\"In Len\"][1]}', f'Out Len Mean: {desc_df[\"Out Len\"][1]}', f'In Rar Mean: {desc_df[\"In Rarity\"][1]}', f'Out Rar Mean: {desc_df[\"Out Rarity\"][1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
