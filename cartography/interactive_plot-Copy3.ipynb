{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b06877-ac3c-416f-8822-5b25c2b46d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import argparse\n",
    "import scipy.stats\n",
    "import scipy.special as special\n",
    "from typing import Dict, List, Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7c76e7-36f3-4ff4-bcd6-5a785f81b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0ded5b-4ced-4360-83e3-71ab5c376772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(file_path: str) -> Any:\n",
    "\twith open(file_path, \"rb\") as handle:\n",
    "\t\treturn pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847ec7e2-db6b-4647-ae9f-aed719ea5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle(file: Any, file_path: str) -> None:\n",
    "    with open(file_path, 'wb') as handle:\n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca42a9d-283b-4386-8dcb-066a7c87a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_freqs(i2s):\n",
    "    in_v = Counter()\n",
    "    out_v = Counter()\n",
    "    \n",
    "    for txt in i2s[\"In\"]:\n",
    "        tokens = txt.split()\n",
    "        in_v.update(tokens)\n",
    "\n",
    "    for txt in i2s[\"Out\"]:\n",
    "        tokens = txt.split()\n",
    "        out_v.update(tokens)\n",
    "    \n",
    "    total = sum(in_v.values())\n",
    "    for k in in_v:\n",
    "        in_v[k] /= total\n",
    "\n",
    "    total = sum(out_v.values())\n",
    "    for k in out_v:\n",
    "        out_v[k] /= total\n",
    "        \n",
    "    return in_v, out_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29dca1a-bdbb-47ed-9ffb-32083a07f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rarity(in_txt, out_txt, in_v, out_v):\n",
    "    in_toks = in_txt.split()\n",
    "    out_toks = out_txt.split()\n",
    "    \n",
    "    in_rarity, out_rarity = 0, 0\n",
    "    in_len, out_len = len(in_toks), len(out_toks)\n",
    "    \n",
    "    for tok in in_toks:\n",
    "        in_rarity += in_v[tok]\n",
    "        \n",
    "    in_rarity /= in_len\n",
    "    \n",
    "    for tok in out_toks:\n",
    "        out_rarity += out_v[tok]\n",
    "    \n",
    "    out_rarity /= out_len\n",
    "    \n",
    "    return -np.log(in_rarity), -np.log(out_rarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc03c329-6f3e-40c9-96b5-5f3fda086106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STRING_TRUNCATE = 50\n",
    "\n",
    "def get_scores(dir_path: str, converge_epoch: int, string_truncate: int) -> Tuple[Dict[int, Dict[str, List[float]]], Dict[str, List[Any]]]:\n",
    "    file_list = os.listdir(dir_path)\n",
    "    idx_to_sentences: Dict[int, Dict[str, str]] = read_pickle(os.path.join(dir_path, \"idx_to_sentences.pickle\"))\n",
    "\n",
    "    file_list = [f for f in file_list if f[:5] == \"epoch\"]\n",
    "    file_list = [f for f in file_list if int(f.split(\"_\")[0].replace(\"epoch\", \"\")) > 3 and int(f.split(\"_\")[0].replace(\"epoch\", \"\")) < converge_epoch]\n",
    "    file_list = sorted(file_list, key= lambda s: int(s.split(\"_\")[1].replace(\"stepidx\", \"\")))\n",
    "\n",
    "    # print(\"Loading files in:\", dir_path)\n",
    "    idxs, ppls, chias, bleus = [], [], [], []\n",
    "    for file_name in file_list:\n",
    "        file_path = f\"{dir_path}/{file_name}\"\n",
    "        # print(file_name)\n",
    "        if \"ppl\" in file_path:\n",
    "            ppls.extend(read_pickle(file_path).tolist())\n",
    "        elif \"chia\" in file_path:\n",
    "            chias.extend(read_pickle(file_path).tolist())\n",
    "        elif \"bleu\" in file_path:\n",
    "            bleus.extend(read_pickle(file_path))\n",
    "        elif \"idx\" in file_path:\n",
    "            idxs.extend(read_pickle(file_path).tolist())\n",
    "        else:\n",
    "            output_csv_name = file_path\n",
    "\n",
    "    items = list(zip(idxs, ppls, chias, bleus))\n",
    "    items = sorted(items, key=lambda i: i[0])\n",
    "    idx_dict: Dict[int, Dict[str, List[float]]] = {}\n",
    "    for item in items:\n",
    "        if item[0] not in idx_dict:\n",
    "            idx_dict[item[0]] = {\"inv_ppl\": [1 / item[1]], \"chia\": [item[2]], \"bleu\": [item[3]]}\n",
    "        else:\n",
    "            idx_dict[item[0]][\"inv_ppl\"].append(1 / item[1])\n",
    "            idx_dict[item[0]][\"chia\"].append(item[2])\n",
    "            idx_dict[item[0]][\"bleu\"].append(item[3])\n",
    "\n",
    "    i2s = {\"Index\": [], \"In\": [], \"Out\": [], \"In Len\": [], \"Out Len\": [], \"In Rarity\": [], \"Out Rarity\": []}\n",
    "\n",
    "    for k, v in idx_to_sentences.items():\n",
    "        i2s[\"Index\"].append(k)\n",
    "        i2s[\"In\"].append(v[\"in\"])\n",
    "        i2s[\"Out\"].append(v[\"out\"])\n",
    "        i2s[\"In Len\"].append(len(v[\"in\"].split()))\n",
    "        i2s[\"Out Len\"].append(len(v[\"out\"].split()))\n",
    "\n",
    "    in_v, out_v = get_word_freqs(i2s)\n",
    "    for k, v in idx_to_sentences.items():\n",
    "        in_rarity, out_rarity = get_rarity(v[\"in\"], v[\"out\"], in_v, out_v)\n",
    "        i2s[\"In Rarity\"].append(in_rarity)\n",
    "        i2s[\"Out Rarity\"].append(out_rarity)\n",
    "\n",
    "    return idx_dict, i2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50fff27f-57cc-4a75-b76e-0efe37123d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_vocab(df):\n",
    "\tin_v = Counter()\n",
    "\tout_v = Counter()\n",
    "    \n",
    "\tfor idx, txt in df[\"In\"].items():\n",
    "\t\ttokens = txt.split()\n",
    "\t\tin_v.update(tokens)\n",
    "         \n",
    "\tfor idx, txt in df[\"Out\"].items():\n",
    "\t\ttokens = txt.split()\n",
    "\t\tout_v.update(tokens)\n",
    "\n",
    "\treturn set(in_v.keys()), set(out_v.keys()), in_v, out_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bde8fd88-8e0c-4848-83c8-440704b82bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(epoch: int, idx_dict: Dict[int, Dict[str, List[float]]], i2s: Dict[str, List[Any]]) -> pd.DataFrame:\n",
    "\tidx_mean_var_dict: Dict[int, Dict[str, Tuple[float, float]]] = {}\n",
    "\tidx_mean_var_list: List[Tuple[int, float, float, float, float, float, float, float, float]] = []\n",
    "\tscore_names = [\"inv_ppl\", \"chia\", \"bleu\"]\n",
    "\tfor idx, scores in idx_dict.items():\n",
    "\t\tscores_list = []\n",
    "\t\tfor score_name in score_names:\n",
    "\t\t\tscore_arr = np.array(scores[score_name][:epoch])\n",
    "\t\t\tmean = score_arr.mean()\n",
    "\t\t\tvar = score_arr.var()\n",
    "\t\t\tscores_list.extend([mean, var])\n",
    "\t\t\n",
    "\t\tidx_mean_var_list.append(tuple((idx, *scores_list)))\n",
    "\n",
    "\ti2s_df = pd.DataFrame.from_dict(i2s)\n",
    "\n",
    "\n",
    "\tdf = pd.DataFrame(idx_mean_var_list, columns =['Index', 'Confidence - Inverse PPL', 'Variability - Inverse PPL', \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'Confidence - CHIA', 'Variability - CHIA', \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'Confidence - BLEU', 'Variability - BLEU'])\n",
    "\n",
    "\tcartography = pd.merge(df, i2s_df, on=\"Index\")\n",
    "\n",
    "\treturn cartography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e43912-8561-4067-9c89-b271bbe079bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scores(dir_path: str, plot_path: str, converge_epoch: int) -> None:\n",
    "\tidx_dict = get_scores(dir_path, plot_path, converge_epoch)\n",
    "\t\n",
    "\tfor epoch in trange(3, converge_epoch, 2):\n",
    "\t\tdf = calculate_statistics(epoch, idx_dict)\n",
    "\n",
    "\t\tplot_types = [\"inv_ppl\", \"chia\", \"bleu\"]\n",
    "\n",
    "\t\tfor plot_type in tqdm(plot_types, \"Plots\"):\n",
    "\t\t\tplot(df, plot_path, str(epoch), plot_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29c2fb0-7401-4cf7-b57c-8451ece5082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_subset(subset_df: pd.DataFrame, ds_name: str, subset_fname: str) -> None:\n",
    "    subset_idx = subset_df[\"Index\"].tolist()\n",
    "    subset_idx = [int(i) for i in subset_idx]\n",
    "    subset_idx = set(subset_idx)\n",
    "    \n",
    "    os.makedirs(os.path.join(\"subsets\", ds_name), exist_ok=True)\n",
    "    write_pickle(subset_idx, os.path.join(\"subsets\", ds_name, subset_fname))\n",
    "    print(f\"subset_idx: {len(subset_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f2ab5c-4900-4104-884e-dc926d1141e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def choose_subset(df: pd.DataFrame, metric: str, criteria: str, ds_name: str, subset_fname:str, ratio:float = 0.33, write=True) -> pd.DataFrame:\n",
    "    assert metric in [\"Inverse PPL\", \"Neg PPL\", \"CHIA\", \"BLEU\"]\n",
    "    assert criteria in [\"Easy to Learn\", \"Ambiguous\", \"Hard to Learn\", \"Random\"]\n",
    "    \n",
    "    if criteria == \"Easy to Learn\":\n",
    "        sort_by = f\"Confidence - {metric}\"\n",
    "        ascending = False\n",
    "    elif criteria == \"Ambiguous\":\n",
    "        sort_by = f\"Variability - {metric}\"\n",
    "        ascending = False\n",
    "    elif criteria == \"Hard to Learn\":\n",
    "        sort_by = f\"Confidence - {metric}\"\n",
    "        ascending = True\n",
    "        \n",
    "    if criteria == \"Random\":\n",
    "        sorted_df = df.sample(frac=1)\n",
    "    else:\n",
    "        sorted_df = df.sort_values(by=[sort_by], ascending=ascending)\n",
    "\n",
    "    sorted_df = sorted_df.reset_index(drop=True)\n",
    "    subset_df = sorted_df.iloc[:int(len(df)*ratio),:]\n",
    "    \n",
    "    all_in_v, all_out_v, _, _ = create_vocab(df)\n",
    "    subset_in_v, subset_out_v, subset_in_v_counts, subset_out_v_counts = create_vocab(subset_df)\n",
    "\n",
    "    add_ex_i = []\n",
    "    remove_ex_i = []\n",
    "    \n",
    "    for i in trange(int(len(df)*ratio), len(df)):\n",
    "        new_in, new_out = sorted_df.iloc[i, 7], sorted_df.iloc[i, 8]\n",
    "        new_in_tokens, new_out_tokens = set(new_in.split()), set(new_out.split())\n",
    "        \n",
    "        if (new_in_tokens - subset_in_v) or (new_out_tokens - subset_out_v):\n",
    "            # print(f\"In vocab dif: {(new_in_tokens - subset_in_v)}\")\n",
    "            # print(f\"Out vocab dif: {(new_out_tokens - subset_out_v)}\")\n",
    "            add_ex_i.append(i)\n",
    "            subset_in_v = subset_in_v.union(new_in_tokens)\n",
    "            subset_out_v = subset_out_v.union(new_out_tokens)\n",
    "            subset_in_v_counts.update(new_in.split())\n",
    "            subset_out_v_counts.update(new_out.split())\n",
    "            \n",
    "    in_counter = subset_in_v_counts\n",
    "    out_counter = subset_out_v_counts\n",
    "    \n",
    "    removed_amount = 0\n",
    "    for i in trange(int(len(df)*ratio)-1, -1, -1):\n",
    "        if len(remove_ex_i) == len(add_ex_i):\n",
    "            break\n",
    "            \n",
    "        ex_in, ex_out = sorted_df.iloc[i, 7], sorted_df.iloc[i, 8]\n",
    "        ex_in_counter, ex_out_counter = Counter(ex_in.split()), Counter(ex_out.split())\n",
    "        \n",
    "        upd_in_counter = in_counter - ex_in_counter\n",
    "        upd_out_counter = out_counter - ex_out_counter\n",
    "        \n",
    "        ex_in_words, ex_out_words = list(set(ex_in.split())), list(set(ex_out.split()))\n",
    "        \n",
    "        remove = True\n",
    "        for word in ex_in_words:\n",
    "            if upd_in_counter[word] <= 1:\n",
    "                remove = False\n",
    "        \n",
    "        for word in ex_out_words:\n",
    "            if upd_out_counter[word] <= 1:\n",
    "                remove = False\n",
    "                \n",
    "        if remove:\n",
    "            in_counter = upd_in_counter\n",
    "            out_counter = upd_out_counter\n",
    "            remove_ex_i.append(i)\n",
    "    \n",
    "    subset_df = pd.concat([subset_df, df.iloc[add_ex_i]])\n",
    "    subset_df = subset_df.drop(remove_ex_i, axis=0)\n",
    "    subset_df = subset_df.reset_index(drop=True)\n",
    "    \n",
    "    assert all_in_v == set(in_counter.keys()), \"The process is wrong\"\n",
    "    assert all_out_v == set(out_counter.keys()), \"The process is wrong 2\"\n",
    "    \n",
    "    if write:\n",
    "        save_subset(subset_df, ds_name, subset_fname)\n",
    "    \n",
    "    print(len(remove_ex_i), len(add_ex_i))\n",
    "    \n",
    "    return subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72b5126d-f2fa-4904-9585-ff9e03ecc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_subsets(df: pd.DataFrame, subset_dfs: List[pd.DataFrame], ds_name: str, subset_fname: str) -> pd.DataFrame:\n",
    "    \n",
    "    combined_set = pd.concat(subset_dfs)\n",
    "    combined_set = combined_set.drop_duplicates(keep=\"first\")\n",
    "    \n",
    "    if len(combined_set) > (len(df) / 2):\n",
    "        combined_set = combined_set.iloc[:int(len(df) / 2)]\n",
    "    else:\n",
    "        count = 0\n",
    "        while len(combined_set) < (len(df) / 2):\n",
    "            example = df.sample(n=1)\n",
    "            if not example.iloc[0][\"In\"] in combined_set['In'].tolist():\n",
    "                combined_set = combined_set.append(example)\n",
    "                \n",
    "    save_subset(combined_set, ds_name, subset_fname)\n",
    "    \n",
    "    return combined_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2075ae2-2739-4421-97be-73ff56a4ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, path_name, extra_path_info, plot_type=\"inv_ppl\"):\n",
    "\tif plot_type == \"inv_ppl\":\n",
    "\t\tfig = px.scatter(df, x=\"Variability - Inverse PPL\", y=\"Confidence - Inverse PPL\", custom_data=['In abbv.', 'Out abbv.', 'In Len', 'Out Len'], color='Confidence - BLEU', range_color=[0,1])\n",
    "\t\tfig.update_layout(yaxis_range=[0, 1])\n",
    "\t\tfig.update_traces(\n",
    "\t\t\thovertemplate=\"<br>\".join([\n",
    "\t\t\t\t\"Variability - Inverse PPL: %{x}\",\n",
    "\t\t\t\t\"Confidence - Inverse PPL: %{y}\",\n",
    "\t\t\t\t\"In: %{customdata[0]}\",\n",
    "\t\t\t\t\"Out: %{customdata[1]}\",\n",
    "                \"In Len: %{customdata[2]}\",\n",
    "                \"Out Len: %{customdata[3]}\", \n",
    "\t\t\t])\n",
    "\t\t)\n",
    "\telif plot_type == \"chia\":\n",
    "\t\tfig = px.scatter(df, x=\"Variability - CHIA\", y=\"Confidence - CHIA\", custom_data=['In abbv.', 'Out abbv.', 'In Len', 'Out Len'], color='Confidence - BLEU', range_color=[0,1])\n",
    "\t\tfig.update_layout(yaxis_range=[0, 1])\n",
    "\t\tfig.update_traces(\n",
    "\t\t\thovertemplate=\"<br>\".join([\n",
    "\t\t\t\t\"Variability - CHIA: %{x}\",\n",
    "\t\t\t\t\"Confidence - CHIA: %{y}\",\n",
    "\t\t\t\t\"In: %{customdata[0]}\",\n",
    "\t\t\t\t\"Out: %{customdata[1]}\",\n",
    "                \"In Len: %{customdata[2]}\",\n",
    "                \"Out Len: %{customdata[3]}\", \n",
    "\t\t\t])\n",
    "\t\t)\n",
    "\telif plot_type == \"bleu\":\n",
    "\t\tfig = px.scatter(df, x=\"Variability - BLEU\", y=\"Confidence - BLEU\", custom_data=['In abbv.', 'Out abbv.', 'In Len', 'Out Len'], color='Confidence - BLEU', range_color=[0,1])\n",
    "\t\tfig.update_layout(yaxis_range=[0, 1])\n",
    "\t\tfig.update_traces(\n",
    "\t\t\thovertemplate=\"<br>\".join([\n",
    "\t\t\t\t\"Variability - BLEU: %{x}\",\n",
    "\t\t\t\t\"Confidence - BLEU: %{y}\",\n",
    "\t\t\t\t\"In: %{customdata[0]}\",\n",
    "\t\t\t\t\"Out: %{customdata[1]}\",\n",
    "                \"In Len: %{customdata[2]}\",\n",
    "                \"Out Len: %{customdata[3]}\", \n",
    "\t\t\t])\n",
    "\t\t)\t\n",
    "\tfig.update_traces(marker=dict(size=3), selector=dict(mode='markers'))\n",
    "\tfig.update_layout(\n",
    "\t\tautosize=False,\n",
    "\t\twidth=800,\n",
    "\t\theight=900\n",
    "\t)\n",
    "\tfig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0386cacd-8d81-4d94-aa31-dcf8606f950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_TRUNCATE = 120\n",
    "\n",
    "mtrc2abv = {\"Inverse PPL\": \"inv_ppl\", \"Neg PPL\": \"neg_ppl\", \"CHIA\": \"chia\", \"BLEU\": \"bleu\"}\n",
    "crit2abv = {\"Easy to Learn\": \"easy_to_learn\", \"Ambiguous\": \"ambiguous\", \"Hard to Learn\": \"hard_to_learn\", \"Random\": \"random\"}\n",
    "create_fname = lambda m, cr, c_e: f\"{mtrc2abv[m]}_{crit2abv[cr]}_{c_e}.pickle\"\n",
    "create_ratio_fname = lambda m, cr, c_e, rto: f\"{mtrc2abv[m]}_{crit2abv[cr]}_{c_e}_{rto}.pickle\"\n",
    "create_comb_fname = lambda m, cr1, cr2, c_e: f\"{mtrc2abv[m]}_{crit2abv[cr1]}_{crit2abv[cr2]}_{c_e}.pickle\"\n",
    "outputs_path = lambda x: f\"../scores/{x}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe29838d-8eea-4f85-bce1-fac2f52e1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i2s = read_pickle(os.path.join(outputs_path(\"cfq\"), \"idx_to_sentences.pickle\"))\n",
    "# i2s_htl = read_pickle(os.path.join(outputs_path(\"cfq\"), \"idx_to_sentences_htl_20.pickle\"))\n",
    "# len(i2s), len(i2s_htl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "883ded4f-6ad1-45c3-823e-0609df0ac4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in: ../scores/cogs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_72904/3021955877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mCONVERGE_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0midx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TRUNCATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0midx_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCRITERIA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_72904/3278148738.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(dir_path, converge_epoch, string_truncate)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mchias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"bleu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mbleus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"idx\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_72904/472232161.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"cogs\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"CHIA\"\n",
    "CRITERIA = \"Hard to Learn\"\n",
    "CONVERGE_EPOCH = 10\n",
    "\n",
    "idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695afffb-e198-4d06-9ecf-5ad749509664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9d900-82eb-4167-bb69-acc1b3da5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a91df2e-2ecb-4d10-a9da-d12b559badf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47872/47872 [00:02<00:00, 21596.55it/s]\n",
      "  0%|          | 0/47871 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 47871\n",
      "0 0\n",
      "Inverse PPL - Hard to Learn:  In Len: 15.21, Out Len: 31.00, In Rarity: 3.44, Out Rarity: 2.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47872/47872 [00:02<00:00, 21351.23it/s]\n",
      "  0%|          | 9/47871 [00:00<00:08, 5744.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 47867\n",
      "9 9\n",
      "Inverse PPL - Easy to Learn:  In Len: 11.86, Out Len: 24.49, In Rarity: 3.49, Out Rarity: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47872/47872 [00:02<00:00, 21787.31it/s]\n",
      "  0%|          | 7/47871 [00:00<00:08, 5430.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 47869\n",
      "7 7\n",
      "Inverse PPL - Ambiguous:  In Len: 12.31, Out Len: 25.08, In Rarity: 3.49, Out Rarity: 2.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47872/47872 [00:02<00:00, 22099.89it/s]\n",
      "  0%|          | 1/47871 [00:00<00:18, 2606.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 47871\n",
      "1 1\n",
      "Inverse PPL - Random:  In Len: 13.53, Out Len: 27.77, In Rarity: 3.47, Out Rarity: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47872/47872 [00:02<00:00, 22674.77it/s]\n",
      "  0%|          | 0/47871 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 47871\n",
      "0 0\n",
      "CHIA - Hard to Learn:  In Len: 15.49, Out Len: 31.71, In Rarity: 3.43, Out Rarity: 2.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47872/47872 [00:02<00:00, 21461.67it/s]\n",
      "  0%|          | 9/47871 [00:00<00:08, 5819.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 47869\n",
      "9 9\n",
      "CHIA - Easy to Learn:  In Len: 11.58, Out Len: 23.78, In Rarity: 3.50, Out Rarity: 2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47872/47872 [00:02<00:00, 22181.51it/s]\n",
      "  0%|          | 3/47871 [00:00<00:11, 4279.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 47871\n",
      "3 3\n",
      "CHIA - Ambiguous:  In Len: 13.99, Out Len: 29.49, In Rarity: 3.45, Out Rarity: 2.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47872/47872 [00:02<00:00, 21856.52it/s]\n",
      "  0%|          | 1/47871 [00:00<00:18, 2641.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 47870\n",
      "1 1\n",
      "CHIA - Random:  In Len: 13.53, Out Len: 27.74, In Rarity: 3.47, Out Rarity: 2.83\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"cfq\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "\n",
    "METRICS = [\"Inverse PPL\", \"CHIA\"]\n",
    "CRITERIA = [\"Hard to Learn\", \"Easy to Learn\", \"Ambiguous\",  \"Random\"]\n",
    "COMBINED_CRITERIA = list(itertools.combinations([\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"], 2))\n",
    "RATIO = 0.5\n",
    "CONVERGE_EPOCHS = [20]\n",
    "\n",
    "for CONVERGE_EPOCH in CONVERGE_EPOCHS:\n",
    "    for METRIC in METRICS:\n",
    "        for CRITERION in CRITERIA:\n",
    "            idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "            df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "            idx_fname = create_ratio_fname(METRIC, CRITERION, CONVERGE_EPOCH, RATIO)\n",
    "            subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, ratio=RATIO)\n",
    "            desc_df = subset_df.describe()\n",
    "            print(f\"{METRIC} - {CRITERION}: \", f'In Len: {desc_df[\"In Len\"][1]:.2f}, Out Len: {desc_df[\"Out Len\"][1]:.2f}, In Rarity: {desc_df[\"In Rarity\"][1]:.2f}, Out Rarity: {desc_df[\"Out Rarity\"][1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeddcebe-c42a-478a-8a46-01403d42d9a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_119797/1740492934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msubset_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mCRITERION\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCRITERIA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0midx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TRUNCATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0midx_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCRITERION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_119797/4128242211.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(dir_path, converge_epoch, string_truncate)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mppls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"chia\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mchias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"bleu\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mbleus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_119797/472232161.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"cfq\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "\n",
    "METRICS = [\"Inverse PPL\", \"CHIA\"]\n",
    "CRITERIA = [\"Hard to Learn\", \"Easy to Learn\", \"Ambiguous\",  \"Random\"]\n",
    "COMBINED_CRITERIA = list(itertools.combinations([\"Hard to Learn\", \"Ambiguous\", \"Easy to Learn\"], 2))\n",
    "CONVERGE_EPOCH = 20\n",
    "\n",
    "for METRIC in METRICS:\n",
    "    for CRITERIA in COMBINED_CRITERIA:\n",
    "        subset_dfs = []\n",
    "        for CRITERION in CRITERIA:\n",
    "            idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "            df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "            idx_fname = create_fname(METRIC, CRITERION, CONVERGE_EPOCH)\n",
    "            subset_df = choose_subset(df, METRIC, CRITERION, DATASET_NAME, idx_fname, write=False)\n",
    "            subset_dfs.append(subset_df)\n",
    "        idx_fname = create_comb_fname(METRIC, CRITERIA[0], CRITERIA[1], CONVERGE_EPOCH)\n",
    "        combined_set_df = combine_subsets(df, subset_dfs, DATASET_NAME, idx_fname)\n",
    "        \n",
    "        print(len(combined_set_df) / len(df))\n",
    "        desc_df = subset_df.describe()\n",
    "        #print(METRIC, CRITERION, f'In Len Mean: {desc_df[\"In Len\"][1]}', f'Out Len Mean: {desc_df[\"Out Len\"][1]}', f'In Rar Mean: {desc_df[\"In Rarity\"][1]}', f'Out Rar Mean: {desc_df[\"Out Rarity\"][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cfa27fba-faa1-484f-b07c-9a0db185e734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Confidence - Inverse PPL</th>\n",
       "      <th>Variability - Inverse PPL</th>\n",
       "      <th>Confidence - CHIA</th>\n",
       "      <th>Variability - CHIA</th>\n",
       "      <th>Confidence - BLEU</th>\n",
       "      <th>Variability - BLEU</th>\n",
       "      <th>In Len</th>\n",
       "      <th>Out Len</th>\n",
       "      <th>In Rarity</th>\n",
       "      <th>Out Rarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47779.527583</td>\n",
       "      <td>0.468341</td>\n",
       "      <td>0.042448</td>\n",
       "      <td>0.708931</td>\n",
       "      <td>0.015143</td>\n",
       "      <td>0.598322</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>16.092325</td>\n",
       "      <td>32.812629</td>\n",
       "      <td>3.430451</td>\n",
       "      <td>2.846160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27656.778684</td>\n",
       "      <td>0.070039</td>\n",
       "      <td>0.013744</td>\n",
       "      <td>0.047820</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.045859</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>4.110981</td>\n",
       "      <td>9.780604</td>\n",
       "      <td>0.176236</td>\n",
       "      <td>0.115194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.041971</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.407099</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.362612</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.097469</td>\n",
       "      <td>2.566864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23861.000000</td>\n",
       "      <td>0.429849</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.681643</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>0.570814</td>\n",
       "      <td>0.012113</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.300994</td>\n",
       "      <td>2.767585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47720.000000</td>\n",
       "      <td>0.484256</td>\n",
       "      <td>0.041778</td>\n",
       "      <td>0.717357</td>\n",
       "      <td>0.014689</td>\n",
       "      <td>0.603874</td>\n",
       "      <td>0.016207</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.399570</td>\n",
       "      <td>2.843143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71780.500000</td>\n",
       "      <td>0.523359</td>\n",
       "      <td>0.051236</td>\n",
       "      <td>0.742551</td>\n",
       "      <td>0.018286</td>\n",
       "      <td>0.630335</td>\n",
       "      <td>0.020929</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>3.521709</td>\n",
       "      <td>2.906923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95741.000000</td>\n",
       "      <td>0.555554</td>\n",
       "      <td>0.137260</td>\n",
       "      <td>0.845808</td>\n",
       "      <td>0.039034</td>\n",
       "      <td>0.743310</td>\n",
       "      <td>0.043566</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>4.686115</td>\n",
       "      <td>3.541374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Index  Confidence - Inverse PPL  Variability - Inverse PPL  \\\n",
       "count  31595.000000              31595.000000               31595.000000   \n",
       "mean   47779.527583                  0.468341                   0.042448   \n",
       "std    27656.778684                  0.070039                   0.013744   \n",
       "min        2.000000                  0.041971                   0.000641   \n",
       "25%    23861.000000                  0.429849                   0.033184   \n",
       "50%    47720.000000                  0.484256                   0.041778   \n",
       "75%    71780.500000                  0.523359                   0.051236   \n",
       "max    95741.000000                  0.555554                   0.137260   \n",
       "\n",
       "       Confidence - CHIA  Variability - CHIA  Confidence - BLEU  \\\n",
       "count       31595.000000        31595.000000       31595.000000   \n",
       "mean            0.708931            0.015143           0.598322   \n",
       "std             0.047820            0.005074           0.045859   \n",
       "min             0.407099            0.001791           0.362612   \n",
       "25%             0.681643            0.011528           0.570814   \n",
       "50%             0.717357            0.014689           0.603874   \n",
       "75%             0.742551            0.018286           0.630335   \n",
       "max             0.845808            0.039034           0.743310   \n",
       "\n",
       "       Variability - BLEU        In Len       Out Len     In Rarity  \\\n",
       "count        31595.000000  31595.000000  31595.000000  31595.000000   \n",
       "mean             0.016847     16.092325     32.812629      3.430451   \n",
       "std              0.006459      4.110981      9.780604      0.176236   \n",
       "min              0.001225      5.000000     11.000000      3.097469   \n",
       "25%              0.012113     13.000000     27.000000      3.300994   \n",
       "50%              0.016207     16.000000     31.000000      3.399570   \n",
       "75%              0.020929     19.000000     38.000000      3.521709   \n",
       "max              0.043566     29.000000     95.000000      4.686115   \n",
       "\n",
       "         Out Rarity  \n",
       "count  31595.000000  \n",
       "mean       2.846160  \n",
       "std        0.115194  \n",
       "min        2.566864  \n",
       "25%        2.767585  \n",
       "50%        2.843143  \n",
       "75%        2.906923  \n",
       "max        3.541374  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "baa9d4c8-eec4-4d68-ad2e-9111397c6953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Confidence - Inverse PPL</th>\n",
       "      <th>Variability - Inverse PPL</th>\n",
       "      <th>Confidence - CHIA</th>\n",
       "      <th>Variability - CHIA</th>\n",
       "      <th>Confidence - BLEU</th>\n",
       "      <th>Variability - BLEU</th>\n",
       "      <th>In Len</th>\n",
       "      <th>Out Len</th>\n",
       "      <th>In Rarity</th>\n",
       "      <th>Out Rarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "      <td>95743.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47871.000000</td>\n",
       "      <td>0.597085</td>\n",
       "      <td>0.052975</td>\n",
       "      <td>0.782078</td>\n",
       "      <td>0.015463</td>\n",
       "      <td>0.669742</td>\n",
       "      <td>0.019771</td>\n",
       "      <td>13.534890</td>\n",
       "      <td>27.743208</td>\n",
       "      <td>3.465526</td>\n",
       "      <td>2.826699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27638.767749</td>\n",
       "      <td>0.111095</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>0.065361</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.066339</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>4.614813</td>\n",
       "      <td>9.115588</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>0.142301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041971</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.407099</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.362612</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.078264</td>\n",
       "      <td>2.566864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23935.500000</td>\n",
       "      <td>0.524352</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>0.741590</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.627365</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.308469</td>\n",
       "      <td>2.733988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47871.000000</td>\n",
       "      <td>0.610798</td>\n",
       "      <td>0.052760</td>\n",
       "      <td>0.792068</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.675890</td>\n",
       "      <td>0.019426</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>3.422888</td>\n",
       "      <td>2.811724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71806.500000</td>\n",
       "      <td>0.681696</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.831535</td>\n",
       "      <td>0.018423</td>\n",
       "      <td>0.716923</td>\n",
       "      <td>0.024243</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.572995</td>\n",
       "      <td>2.892543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95742.000000</td>\n",
       "      <td>0.890003</td>\n",
       "      <td>0.137260</td>\n",
       "      <td>0.937200</td>\n",
       "      <td>0.039919</td>\n",
       "      <td>0.856787</td>\n",
       "      <td>0.053432</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>4.781837</td>\n",
       "      <td>3.576896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Index  Confidence - Inverse PPL  Variability - Inverse PPL  \\\n",
       "count  95743.000000              95743.000000               95743.000000   \n",
       "mean   47871.000000                  0.597085                   0.052975   \n",
       "std    27638.767749                  0.111095                   0.015563   \n",
       "min        0.000000                  0.041971                   0.000641   \n",
       "25%    23935.500000                  0.524352                   0.042325   \n",
       "50%    47871.000000                  0.610798                   0.052760   \n",
       "75%    71806.500000                  0.681696                   0.063200   \n",
       "max    95742.000000                  0.890003                   0.137260   \n",
       "\n",
       "       Confidence - CHIA  Variability - CHIA  Confidence - BLEU  \\\n",
       "count       95743.000000        95743.000000       95743.000000   \n",
       "mean            0.782078            0.015463           0.669742   \n",
       "std             0.065361            0.004721           0.066339   \n",
       "min             0.407099            0.001791           0.362612   \n",
       "25%             0.741590            0.012121           0.627365   \n",
       "50%             0.792068            0.015118           0.675890   \n",
       "75%             0.831535            0.018423           0.716923   \n",
       "max             0.937200            0.039919           0.856787   \n",
       "\n",
       "       Variability - BLEU        In Len       Out Len     In Rarity  \\\n",
       "count        95743.000000  95743.000000  95743.000000  95743.000000   \n",
       "mean             0.019771     13.534890     27.743208      3.465526   \n",
       "std              0.006750      4.614813      9.115588      0.223521   \n",
       "min              0.001225      3.000000     11.000000      3.078264   \n",
       "25%              0.014906     10.000000     21.000000      3.308469   \n",
       "50%              0.019426     13.000000     26.000000      3.422888   \n",
       "75%              0.024243     17.000000     33.000000      3.572995   \n",
       "max              0.053432     29.000000     95.000000      4.781837   \n",
       "\n",
       "         Out Rarity  \n",
       "count  95743.000000  \n",
       "mean       2.826699  \n",
       "std        0.142301  \n",
       "min        2.566864  \n",
       "25%        2.733988  \n",
       "50%        2.811724  \n",
       "75%        2.892543  \n",
       "max        3.576896  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6b72b236-10ee-4298-a123-dce854744882",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39124/3698100315.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mCONVERGE_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0midx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TRUNCATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0midx_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCRITERIA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONVERGE_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_39124/3278148738.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(dir_path, converge_epoch, string_truncate)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverge_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_truncate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0midx_to_sentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"idx_to_sentences.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"scan_length\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"CHIA\"\n",
    "CRITERIA = \"Hard to Learn\"\n",
    "CONVERGE_EPOCH = 30\n",
    "\n",
    "idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84eee1-dea9-4283-9d3a-aca5858b5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecc0c5-917c-4bc7-82e8-fc9960a8facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a5290f9-8645-4c19-ab8a-a4807b93f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in: ../scores/scan_jump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9829/9829 [00:00<00:00, 22867.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In vocab dif: {'jump'}\n",
      "Out vocab dif: {'I_JUMP'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4841 [00:00<00:01, 4009.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"scan_jump\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"CHIA\"\n",
    "CRITERIA = \"Hard to Learn\"\n",
    "CONVERGE_EPOCH = 30\n",
    "\n",
    "idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db220853-5e76-4f14-a28d-ce15f987b8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Confidence - Inverse PPL</th>\n",
       "      <th>Variability - Inverse PPL</th>\n",
       "      <th>Confidence - CHIA</th>\n",
       "      <th>Variability - CHIA</th>\n",
       "      <th>Confidence - BLEU</th>\n",
       "      <th>Variability - BLEU</th>\n",
       "      <th>In Len</th>\n",
       "      <th>Out Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14670.00000</td>\n",
       "      <td>14670.000000</td>\n",
       "      <td>1.467000e+04</td>\n",
       "      <td>14670.000000</td>\n",
       "      <td>1.467000e+04</td>\n",
       "      <td>14670.000000</td>\n",
       "      <td>14670.000000</td>\n",
       "      <td>14670.000000</td>\n",
       "      <td>14670.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7334.50000</td>\n",
       "      <td>0.811877</td>\n",
       "      <td>3.109984e-02</td>\n",
       "      <td>0.870645</td>\n",
       "      <td>1.570789e-02</td>\n",
       "      <td>0.675831</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>6.643763</td>\n",
       "      <td>12.727812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4235.00856</td>\n",
       "      <td>0.092899</td>\n",
       "      <td>2.224530e-02</td>\n",
       "      <td>0.069127</td>\n",
       "      <td>1.362532e-02</td>\n",
       "      <td>0.213221</td>\n",
       "      <td>0.011695</td>\n",
       "      <td>2.208942</td>\n",
       "      <td>9.162258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.276485</td>\n",
       "      <td>3.660198e-10</td>\n",
       "      <td>0.529350</td>\n",
       "      <td>3.663849e-10</td>\n",
       "      <td>0.131650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3667.25000</td>\n",
       "      <td>0.751254</td>\n",
       "      <td>1.256169e-02</td>\n",
       "      <td>0.823701</td>\n",
       "      <td>4.239430e-03</td>\n",
       "      <td>0.622686</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7334.50000</td>\n",
       "      <td>0.798249</td>\n",
       "      <td>2.819625e-02</td>\n",
       "      <td>0.861600</td>\n",
       "      <td>1.211250e-02</td>\n",
       "      <td>0.717946</td>\n",
       "      <td>0.013982</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11001.75000</td>\n",
       "      <td>0.869623</td>\n",
       "      <td>4.748547e-02</td>\n",
       "      <td>0.920733</td>\n",
       "      <td>2.486033e-02</td>\n",
       "      <td>0.829987</td>\n",
       "      <td>0.023542</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14669.00000</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>1.394370e-01</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>7.669706e-02</td>\n",
       "      <td>0.969229</td>\n",
       "      <td>0.068510</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Index  Confidence - Inverse PPL  Variability - Inverse PPL  \\\n",
       "count  14670.00000              14670.000000               1.467000e+04   \n",
       "mean    7334.50000                  0.811877               3.109984e-02   \n",
       "std     4235.00856                  0.092899               2.224530e-02   \n",
       "min        0.00000                  0.276485               3.660198e-10   \n",
       "25%     3667.25000                  0.751254               1.256169e-02   \n",
       "50%     7334.50000                  0.798249               2.819625e-02   \n",
       "75%    11001.75000                  0.869623               4.748547e-02   \n",
       "max    14669.00000                  0.999992               1.394370e-01   \n",
       "\n",
       "       Confidence - CHIA  Variability - CHIA  Confidence - BLEU  \\\n",
       "count       14670.000000        1.467000e+04       14670.000000   \n",
       "mean            0.870645        1.570789e-02           0.675831   \n",
       "std             0.069127        1.362532e-02           0.213221   \n",
       "min             0.529350        3.663849e-10           0.131650   \n",
       "25%             0.823701        4.239430e-03           0.622686   \n",
       "50%             0.861600        1.211250e-02           0.717946   \n",
       "75%             0.920733        2.486033e-02           0.829987   \n",
       "max             0.999992        7.669706e-02           0.969229   \n",
       "\n",
       "       Variability - BLEU        In Len       Out Len  \n",
       "count        14670.000000  14670.000000  14670.000000  \n",
       "mean             0.015743      6.643763     12.727812  \n",
       "std              0.011695      2.208942      9.162258  \n",
       "min              0.000000      1.000000      1.000000  \n",
       "25%              0.006194      6.000000      6.000000  \n",
       "50%              0.013982      7.000000     10.000000  \n",
       "75%              0.023542      8.000000     18.000000  \n",
       "max              0.068510      9.000000     48.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5761e02a-6200-4e0e-9aa7-0dcb4652c6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Confidence - Inverse PPL</th>\n",
       "      <th>Variability - Inverse PPL</th>\n",
       "      <th>Confidence - CHIA</th>\n",
       "      <th>Variability - CHIA</th>\n",
       "      <th>Confidence - BLEU</th>\n",
       "      <th>Variability - BLEU</th>\n",
       "      <th>In Len</th>\n",
       "      <th>Out Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4841.000000</td>\n",
       "      <td>4841.000000</td>\n",
       "      <td>4841.000000</td>\n",
       "      <td>4841.000000</td>\n",
       "      <td>4841.000000</td>\n",
       "      <td>4841.000000</td>\n",
       "      <td>4841.000000</td>\n",
       "      <td>4841.000000</td>\n",
       "      <td>4841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7356.418715</td>\n",
       "      <td>0.720289</td>\n",
       "      <td>0.052241</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.632905</td>\n",
       "      <td>0.025675</td>\n",
       "      <td>6.817187</td>\n",
       "      <td>8.457963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4260.666859</td>\n",
       "      <td>0.048495</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>0.034889</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>0.091986</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>1.349258</td>\n",
       "      <td>3.931534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276485</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.529350</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.249460</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3697.000000</td>\n",
       "      <td>0.698229</td>\n",
       "      <td>0.039868</td>\n",
       "      <td>0.781987</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>0.576173</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7295.000000</td>\n",
       "      <td>0.730197</td>\n",
       "      <td>0.052269</td>\n",
       "      <td>0.806718</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>0.650905</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10996.000000</td>\n",
       "      <td>0.753725</td>\n",
       "      <td>0.063736</td>\n",
       "      <td>0.823363</td>\n",
       "      <td>0.037331</td>\n",
       "      <td>0.698421</td>\n",
       "      <td>0.032411</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14666.000000</td>\n",
       "      <td>0.812255</td>\n",
       "      <td>0.139437</td>\n",
       "      <td>0.835363</td>\n",
       "      <td>0.076697</td>\n",
       "      <td>0.856253</td>\n",
       "      <td>0.068510</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Index  Confidence - Inverse PPL  Variability - Inverse PPL  \\\n",
       "count   4841.000000               4841.000000                4841.000000   \n",
       "mean    7356.418715                  0.720289                   0.052241   \n",
       "std     4260.666859                  0.048495                   0.017266   \n",
       "min        1.000000                  0.276485                   0.007619   \n",
       "25%     3697.000000                  0.698229                   0.039868   \n",
       "50%     7295.000000                  0.730197                   0.052269   \n",
       "75%    10996.000000                  0.753725                   0.063736   \n",
       "max    14666.000000                  0.812255                   0.139437   \n",
       "\n",
       "       Confidence - CHIA  Variability - CHIA  Confidence - BLEU  \\\n",
       "count        4841.000000         4841.000000        4841.000000   \n",
       "mean            0.797500            0.029197           0.632905   \n",
       "std             0.034889            0.011621           0.091986   \n",
       "min             0.529350            0.002780           0.249460   \n",
       "25%             0.781987            0.020214           0.576173   \n",
       "50%             0.806718            0.028243           0.650905   \n",
       "75%             0.823363            0.037331           0.698421   \n",
       "max             0.835363            0.076697           0.856253   \n",
       "\n",
       "       Variability - BLEU       In Len      Out Len  \n",
       "count         4841.000000  4841.000000  4841.000000  \n",
       "mean             0.025675     6.817187     8.457963  \n",
       "std              0.010002     1.349258     3.931534  \n",
       "min              0.002889     1.000000     1.000000  \n",
       "25%              0.018181     6.000000     5.000000  \n",
       "50%              0.024752     7.000000     8.000000  \n",
       "75%              0.032411     8.000000    11.000000  \n",
       "max              0.068510     9.000000    24.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d139b1c8-6c44-48a2-aa6e-936c7a156a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e0137f9-7d90-4afb-a054-de2cc56e0324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in: ../scores/pcfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55053/55053 [00:02<00:00, 22886.98it/s]\n",
      "  0%|          | 0/27115 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"pcfg\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"CHIA\"\n",
    "CRITERIA = \"Hard to Learn\"\n",
    "CONVERGE_EPOCH = 140\n",
    "\n",
    "idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "651b6c1b-9b5e-4cdf-b88c-d86b79dbf281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Confidence - Inverse PPL</th>\n",
       "      <th>Variability - Inverse PPL</th>\n",
       "      <th>Confidence - CHIA</th>\n",
       "      <th>Variability - CHIA</th>\n",
       "      <th>Confidence - BLEU</th>\n",
       "      <th>Variability - BLEU</th>\n",
       "      <th>In Len</th>\n",
       "      <th>Out Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82168.000000</td>\n",
       "      <td>82168.000000</td>\n",
       "      <td>82168.000000</td>\n",
       "      <td>82168.000000</td>\n",
       "      <td>82168.000000</td>\n",
       "      <td>82168.000000</td>\n",
       "      <td>82168.000000</td>\n",
       "      <td>82168.000000</td>\n",
       "      <td>82168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41083.500000</td>\n",
       "      <td>0.657339</td>\n",
       "      <td>0.126839</td>\n",
       "      <td>0.712272</td>\n",
       "      <td>0.103254</td>\n",
       "      <td>0.506744</td>\n",
       "      <td>0.061316</td>\n",
       "      <td>17.699883</td>\n",
       "      <td>8.895884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23720.002797</td>\n",
       "      <td>0.124807</td>\n",
       "      <td>0.033832</td>\n",
       "      <td>0.102243</td>\n",
       "      <td>0.033217</td>\n",
       "      <td>0.068689</td>\n",
       "      <td>0.033513</td>\n",
       "      <td>9.410670</td>\n",
       "      <td>7.794699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.186722</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.175278</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20541.750000</td>\n",
       "      <td>0.597530</td>\n",
       "      <td>0.105946</td>\n",
       "      <td>0.658073</td>\n",
       "      <td>0.079857</td>\n",
       "      <td>0.472124</td>\n",
       "      <td>0.031961</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41083.500000</td>\n",
       "      <td>0.680250</td>\n",
       "      <td>0.131590</td>\n",
       "      <td>0.726545</td>\n",
       "      <td>0.104896</td>\n",
       "      <td>0.520684</td>\n",
       "      <td>0.060412</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61625.250000</td>\n",
       "      <td>0.743193</td>\n",
       "      <td>0.154147</td>\n",
       "      <td>0.784396</td>\n",
       "      <td>0.130419</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.088102</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82167.000000</td>\n",
       "      <td>0.981210</td>\n",
       "      <td>0.194359</td>\n",
       "      <td>0.984010</td>\n",
       "      <td>0.176240</td>\n",
       "      <td>0.754878</td>\n",
       "      <td>0.149322</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>736.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Index  Confidence - Inverse PPL  Variability - Inverse PPL  \\\n",
       "count  82168.000000              82168.000000               82168.000000   \n",
       "mean   41083.500000                  0.657339                   0.126839   \n",
       "std    23720.002797                  0.124807                   0.033832   \n",
       "min        0.000000                  0.096914                   0.003238   \n",
       "25%    20541.750000                  0.597530                   0.105946   \n",
       "50%    41083.500000                  0.680250                   0.131590   \n",
       "75%    61625.250000                  0.743193                   0.154147   \n",
       "max    82167.000000                  0.981210                   0.194359   \n",
       "\n",
       "       Confidence - CHIA  Variability - CHIA  Confidence - BLEU  \\\n",
       "count       82168.000000        82168.000000       82168.000000   \n",
       "mean            0.712272            0.103254           0.506744   \n",
       "std             0.102243            0.033217           0.068689   \n",
       "min             0.186722            0.001352           0.175278   \n",
       "25%             0.658073            0.079857           0.472124   \n",
       "50%             0.726545            0.104896           0.520684   \n",
       "75%             0.784396            0.130419           0.556863   \n",
       "max             0.984010            0.176240           0.754878   \n",
       "\n",
       "       Variability - BLEU        In Len       Out Len  \n",
       "count        82168.000000  82168.000000  82168.000000  \n",
       "mean             0.061316     17.699883      8.895884  \n",
       "std              0.033513      9.410670      7.794699  \n",
       "min              0.000825      3.000000      2.000000  \n",
       "25%              0.031961     11.000000      4.000000  \n",
       "50%              0.060412     16.000000      7.000000  \n",
       "75%              0.088102     23.000000     11.000000  \n",
       "max              0.149322     71.000000    736.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b56b342e-9e75-42d5-b608-656081535685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Confidence - Inverse PPL</th>\n",
       "      <th>Variability - Inverse PPL</th>\n",
       "      <th>Confidence - CHIA</th>\n",
       "      <th>Variability - CHIA</th>\n",
       "      <th>Confidence - BLEU</th>\n",
       "      <th>Variability - BLEU</th>\n",
       "      <th>In Len</th>\n",
       "      <th>Out Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "      <td>27115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41163.802508</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>0.139458</td>\n",
       "      <td>0.597169</td>\n",
       "      <td>0.127739</td>\n",
       "      <td>0.501446</td>\n",
       "      <td>0.090461</td>\n",
       "      <td>24.506362</td>\n",
       "      <td>15.096810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23767.251788</td>\n",
       "      <td>0.103914</td>\n",
       "      <td>0.033883</td>\n",
       "      <td>0.079702</td>\n",
       "      <td>0.025657</td>\n",
       "      <td>0.069216</td>\n",
       "      <td>0.025137</td>\n",
       "      <td>9.282645</td>\n",
       "      <td>10.553437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.096914</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.186722</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.175278</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20653.000000</td>\n",
       "      <td>0.464303</td>\n",
       "      <td>0.120784</td>\n",
       "      <td>0.561201</td>\n",
       "      <td>0.113865</td>\n",
       "      <td>0.466188</td>\n",
       "      <td>0.075694</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41280.000000</td>\n",
       "      <td>0.548299</td>\n",
       "      <td>0.149316</td>\n",
       "      <td>0.621488</td>\n",
       "      <td>0.133957</td>\n",
       "      <td>0.520229</td>\n",
       "      <td>0.094642</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61746.500000</td>\n",
       "      <td>0.596771</td>\n",
       "      <td>0.165431</td>\n",
       "      <td>0.657101</td>\n",
       "      <td>0.146735</td>\n",
       "      <td>0.551279</td>\n",
       "      <td>0.108756</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82167.000000</td>\n",
       "      <td>0.658802</td>\n",
       "      <td>0.194359</td>\n",
       "      <td>0.683924</td>\n",
       "      <td>0.176240</td>\n",
       "      <td>0.660227</td>\n",
       "      <td>0.149322</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>736.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Index  Confidence - Inverse PPL  Variability - Inverse PPL  \\\n",
       "count  27115.000000              27115.000000               27115.000000   \n",
       "mean   41163.802508                  0.517232                   0.139458   \n",
       "std    23767.251788                  0.103914                   0.033883   \n",
       "min       14.000000                  0.096914                   0.005126   \n",
       "25%    20653.000000                  0.464303                   0.120784   \n",
       "50%    41280.000000                  0.548299                   0.149316   \n",
       "75%    61746.500000                  0.596771                   0.165431   \n",
       "max    82167.000000                  0.658802                   0.194359   \n",
       "\n",
       "       Confidence - CHIA  Variability - CHIA  Confidence - BLEU  \\\n",
       "count       27115.000000        27115.000000       27115.000000   \n",
       "mean            0.597169            0.127739           0.501446   \n",
       "std             0.079702            0.025657           0.069216   \n",
       "min             0.186722            0.014304           0.175278   \n",
       "25%             0.561201            0.113865           0.466188   \n",
       "50%             0.621488            0.133957           0.520229   \n",
       "75%             0.657101            0.146735           0.551279   \n",
       "max             0.683924            0.176240           0.660227   \n",
       "\n",
       "       Variability - BLEU        In Len       Out Len  \n",
       "count        27115.000000  27115.000000  27115.000000  \n",
       "mean             0.090461     24.506362     15.096810  \n",
       "std              0.025137      9.282645     10.553437  \n",
       "min              0.003750      4.000000      2.000000  \n",
       "25%              0.075694     18.000000     10.000000  \n",
       "50%              0.094642     23.000000     13.000000  \n",
       "75%              0.108756     30.000000     18.000000  \n",
       "max              0.149322     71.000000    736.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf9bfb-32c1-468e-9f15-60493c553ec8",
   "metadata": {},
   "source": [
    "subset_df_in = set(subset_df[\"In\"].tolist())\n",
    "subset_df_out = set(subset_df[\"Out\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553192c-6d24-4ad5-9b8f-6b39117d8bb1",
   "metadata": {},
   "source": [
    "subset_pkl = read_pickle(\"../scores/cogs/idx_to_sentences.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a7e7f-5c17-4ec5-8be5-8d01353590ef",
   "metadata": {},
   "source": [
    "subset_pkl_in = []\n",
    "subset_pkl_out = []\n",
    "\n",
    "for i, text in subset_pkl.items():\n",
    "    subset_pkl_in.append(text[\"in\"])\n",
    "    subset_pkl_out.append(text[\"out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab763559-2449-410a-960b-d999ebc0e234",
   "metadata": {},
   "source": [
    "subset_pkl_in = set(subset_pkl_in)\n",
    "subset_pkl_out = set(subset_pkl_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edd506-124d-4657-ba1e-906fb731f680",
   "metadata": {},
   "source": [
    "subset_df_in - subset_pkl_in, len(subset_df_in), len(subset_pkl_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
