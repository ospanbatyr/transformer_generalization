{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b06877-ac3c-416f-8822-5b25c2b46d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle5 as pickle\n",
    "import plotly.express as px\n",
    "import argparse\n",
    "import scipy.stats\n",
    "import scipy.special as special\n",
    "from typing import Dict, List, Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7c76e7-36f3-4ff4-bcd6-5a785f81b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0ded5b-4ced-4360-83e3-71ab5c376772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(file_path: str) -> Any:\n",
    "\twith open(file_path, \"rb\") as handle:\n",
    "\t\treturn pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847ec7e2-db6b-4647-ae9f-aed719ea5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle(file: Any, file_path: str) -> None:\n",
    "    with open(file_path, 'wb') as handle:\n",
    "        pickle.dump(file, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc03c329-6f3e-40c9-96b5-5f3fda086106",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_TRUNCATE = 50\n",
    "\n",
    "def get_scores(dir_path: str, converge_epoch: int, string_truncate: int, min_epoch: int = 3) -> Tuple[Dict[int, Dict[str, List[float]]], Dict[str, List[Any]]]:\n",
    "\tfile_list = os.listdir(dir_path)\n",
    "\tidx_to_sentences: Dict[int, Dict[str, str]] = read_pickle(os.path.join(dir_path, \"idx_to_sentences.pickle\"))\n",
    "\n",
    "\tfile_list = [f for f in file_list if f[:5] == \"epoch\"]\n",
    "\tfile_list = [f for f in file_list if int(f.split(\"_\")[0].replace(\"epoch\", \"\")) > min_epoch and int(f.split(\"_\")[0].replace(\"epoch\", \"\")) < converge_epoch]\n",
    "\tfile_list = sorted(file_list, key= lambda s: int(s.split(\"_\")[1].replace(\"stepidx\", \"\")))\n",
    "\n",
    "\tprint(\"Loading files in:\", dir_path)\n",
    "\tidxs, ppls, chias, bleus = [], [], [], []\n",
    "\tfor file_name in file_list:\n",
    "\t\tfile_path = f\"{dir_path}/{file_name}\"\n",
    "\t\t#Â print(file_name)\n",
    "\t\tif \"ppl\" in file_path:\n",
    "\t\t\tppls.extend(read_pickle(file_path).tolist())\n",
    "\t\telif \"chia\" in file_path:\n",
    "\t\t\tchias.extend(read_pickle(file_path).tolist())\n",
    "\t\telif \"bleu\" in file_path:\n",
    "\t\t\tbleus.extend(read_pickle(file_path))\n",
    "\t\telif \"idx\" in file_path:\n",
    "\t\t\tidxs.extend(read_pickle(file_path).tolist())\n",
    "\t\telse:\n",
    "\t\t\toutput_csv_name = file_path\n",
    "\n",
    "\titems = list(zip(idxs, ppls, chias, bleus))\n",
    "\titems = sorted(items, key=lambda i: i[0])\n",
    "\tidx_dict: Dict[int, Dict[str, List[float]]] = {}\n",
    "\tfor item in items:\n",
    "\t\tif item[0] not in idx_dict:\n",
    "\t\t\tidx_dict[item[0]] = {\"inv_ppl\": [1 / item[1]], \"chia\": [item[2]], \"bleu\": [item[3]]}\n",
    "\t\telse:\n",
    "\t\t\tidx_dict[item[0]][\"inv_ppl\"].append(1 / item[1])\n",
    "\t\t\tidx_dict[item[0]][\"chia\"].append(item[2])\n",
    "\t\t\tidx_dict[item[0]][\"bleu\"].append(item[3])\n",
    "\n",
    "\ti2s = {\"Index\": [], \"In\": [], \"Out\": [], \"In abbv.\": [], \"Out abbv.\": [], \"In Len\": [], \"Out Len\": []}\n",
    "\tfor k, v in idx_to_sentences.items():\n",
    "\t\ti2s[\"Index\"].append(k)\n",
    "\t\ti2s[\"In\"].append(v[\"in\"])\n",
    "\t\ti2s[\"Out\"].append(v[\"out\"])\n",
    "\t\ti2s[\"In abbv.\"].append(v[\"in\"][:STRING_TRUNCATE])\n",
    "\t\ti2s[\"Out abbv.\"].append(v[\"out\"][:STRING_TRUNCATE])\n",
    "\t\ti2s[\"In Len\"].append(len(v[\"in\"].split()))\n",
    "\t\ti2s[\"Out Len\"].append(len(v[\"out\"].split()))\n",
    "\n",
    "\treturn idx_dict, i2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fff27f-57cc-4a75-b76e-0efe37123d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def create_vocab(df):\n",
    "\tin_v = Counter()\n",
    "\tout_v = Counter()\n",
    "    \n",
    "\tfor idx, txt in df[\"In\"].items():\n",
    "\t\ttokens = txt.split()\n",
    "\t\tin_v.update(tokens)\n",
    "         \n",
    "\tfor idx, txt in df[\"Out\"].items():\n",
    "\t\ttokens = txt.split()\n",
    "\t\tout_v.update(tokens)\n",
    "\n",
    "\treturn set(in_v.keys()), set(out_v.keys()), in_v, out_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde8fd88-8e0c-4848-83c8-440704b82bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(epoch: int, idx_dict: Dict[int, Dict[str, List[float]]], i2s: Dict[str, List[Any]]) -> pd.DataFrame:\n",
    "\tidx_mean_var_dict: Dict[int, Dict[str, Tuple[float, float]]] = {}\n",
    "\tidx_mean_var_list: List[Tuple[int, float, float, float, float, float, float, float, float]] = []\n",
    "\tscore_names = [\"inv_ppl\", \"chia\", \"bleu\"]\n",
    "\tfor idx, scores in idx_dict.items():\n",
    "\t\tscores_list = []\n",
    "\t\tfor score_name in score_names:\n",
    "\t\t\tscore_arr = np.array(scores[score_name][:epoch])\n",
    "\t\t\tmean = score_arr.mean()\n",
    "\t\t\tvar = score_arr.var()\n",
    "\t\t\tscores_list.extend([mean, var])\n",
    "\t\t\n",
    "\t\tidx_mean_var_list.append(tuple((idx, *scores_list)))\n",
    "\n",
    "\ti2s_df = pd.DataFrame.from_dict(i2s)\n",
    "\n",
    "\n",
    "\tdf = pd.DataFrame(idx_mean_var_list, columns =['Index', 'Confidence - Inverse PPL', 'Variability - Inverse PPL', \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'Confidence - CHIA', 'Variability - CHIA', \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t'Confidence - BLEU', 'Variability - BLEU'])\n",
    "\n",
    "\tcartography = pd.merge(df, i2s_df, on=\"Index\")\n",
    "\n",
    "\treturn cartography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e43912-8561-4067-9c89-b271bbe079bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scores(dir_path: str, plot_path: str, converge_epoch: int) -> None:\n",
    "\tidx_dict = get_scores(dir_path, plot_path, converge_epoch)\n",
    "\t\n",
    "\tfor epoch in trange(3, converge_epoch, 2):\n",
    "\t\tdf = calculate_statistics(epoch, idx_dict)\n",
    "\n",
    "\t\tplot_types = [\"inv_ppl\", \"chia\", \"bleu\"]\n",
    "\n",
    "\t\tfor plot_type in tqdm(plot_types, \"Plots\"):\n",
    "\t\t\tplot(df, plot_path, str(epoch), plot_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9a05e2-6ee9-41eb-8443-9c13ba10b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_subset(subset_df: pd.DataFrame, ds_name: str, subset_fname: str) -> None:\n",
    "    subset_idx = subset_df[\"Index\"].tolist()\n",
    "    subset_idx = [int(i) for i in subset_idx]\n",
    "    subset_idx = set(subset_idx)\n",
    "    \n",
    "    os.makedirs(os.path.join(\"subsets\", ds_name), exist_ok=True)\n",
    "    write_pickle(subset_idx, os.path.join(\"subsets\", ds_name, subset_fname))\n",
    "    print(f\"subset_idx: {len(subset_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f2ab5c-4900-4104-884e-dc926d1141e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def choose_subset(df: pd.DataFrame, metric: str, criteria: str, ds_name: str, subset_fname:str, ratio:float = 0.33, write=True) -> pd.DataFrame:\n",
    "    assert metric in [\"Inverse PPL\", \"Neg PPL\", \"CHIA\", \"BLEU\"]\n",
    "    assert criteria in [\"Easy to Learn\", \"Ambiguous\", \"Hard to Learn\", \"Random\"]\n",
    "    \n",
    "    if criteria == \"Easy to Learn\":\n",
    "        sort_by = f\"Confidence - {metric}\"\n",
    "        ascending = False\n",
    "    elif criteria == \"Ambiguous\":\n",
    "        sort_by = f\"Variability - {metric}\"\n",
    "        ascending = False\n",
    "    elif criteria == \"Hard to Learn\":\n",
    "        sort_by = f\"Confidence - {metric}\"\n",
    "        ascending = True\n",
    "        \n",
    "    if criteria == \"Random\":\n",
    "        sorted_df = df.sample(frac=1)\n",
    "    else:\n",
    "        sorted_df = df.sort_values(by=[sort_by], ascending=ascending)\n",
    "\n",
    "    sorted_df = sorted_df.reset_index(drop=True)\n",
    "    subset_df = sorted_df.iloc[:int(len(df)*ratio),:]\n",
    "    \n",
    "    all_in_v, all_out_v, _, _ = create_vocab(df)\n",
    "    subset_in_v, subset_out_v, subset_in_v_counts, subset_out_v_counts = create_vocab(subset_df)\n",
    "\n",
    "    add_ex_i = []\n",
    "    remove_ex_i = []\n",
    "    \n",
    "    for i in trange(int(len(df)*ratio), len(df)):\n",
    "        new_in, new_out = sorted_df.iloc[i, 7], sorted_df.iloc[i, 8]\n",
    "        new_in_tokens, new_out_tokens = set(new_in.split()), set(new_out.split())\n",
    "        \n",
    "        if (new_in_tokens - subset_in_v) or (new_out_tokens - subset_out_v):\n",
    "            # print(f\"In vocab dif: {(new_in_tokens - subset_in_v)}\")\n",
    "            # print(f\"Out vocab dif: {(new_out_tokens - subset_out_v)}\")\n",
    "            add_ex_i.append(i)\n",
    "            subset_in_v = subset_in_v.union(new_in_tokens)\n",
    "            subset_out_v = subset_out_v.union(new_out_tokens)\n",
    "            subset_in_v_counts.update(new_in.split())\n",
    "            subset_out_v_counts.update(new_out.split())\n",
    "            \n",
    "    in_counter = subset_in_v_counts\n",
    "    out_counter = subset_out_v_counts\n",
    "    \n",
    "    removed_amount = 0\n",
    "    for i in trange(int(len(df)*ratio)-1, -1, -1):\n",
    "        if len(remove_ex_i) == len(add_ex_i):\n",
    "            break\n",
    "            \n",
    "        ex_in, ex_out = sorted_df.iloc[i, 7], sorted_df.iloc[i, 8]\n",
    "        ex_in_counter, ex_out_counter = Counter(ex_in.split()), Counter(ex_out.split())\n",
    "        \n",
    "        upd_in_counter = in_counter - ex_in_counter\n",
    "        upd_out_counter = out_counter - ex_out_counter\n",
    "        \n",
    "        ex_in_words, ex_out_words = list(set(ex_in.split())), list(set(ex_out.split()))\n",
    "        \n",
    "        remove = True\n",
    "        for word in ex_in_words:\n",
    "            if upd_in_counter[word] <= 1:\n",
    "                remove = False\n",
    "        \n",
    "        for word in ex_out_words:\n",
    "            if upd_out_counter[word] <= 1:\n",
    "                remove = False\n",
    "                \n",
    "        if remove:\n",
    "            in_counter = upd_in_counter\n",
    "            out_counter = upd_out_counter\n",
    "            remove_ex_i.append(i)\n",
    "    \n",
    "    subset_df = pd.concat([subset_df, df.iloc[add_ex_i]])\n",
    "    subset_df = subset_df.drop(remove_ex_i, axis=0)\n",
    "    subset_df = subset_df.reset_index(drop=True)\n",
    "    \n",
    "    assert all_in_v == set(in_counter.keys()), \"The process is wrong\"\n",
    "    assert all_out_v == set(out_counter.keys()), \"The process is wrong 2\"\n",
    "    \n",
    "    if write:\n",
    "        save_subset(subset_df, ds_name, subset_fname)\n",
    "    \n",
    "    print(len(remove_ex_i), len(add_ex_i))\n",
    "    \n",
    "    return subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2075ae2-2739-4421-97be-73ff56a4ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, plot_type=\"inv_ppl\"):\n",
    "\tif plot_type == \"inv_ppl\":\n",
    "\t\tfig = px.scatter(df, x=\"Variability - Inverse PPL\", y=\"Confidence - Inverse PPL\", custom_data=['In abbv.', 'Out abbv.', 'In Len', 'Out Len', 'Confidence - BLEU'], color='Confidence - BLEU', range_color=[0,1])\n",
    "\t\tfig.update_layout(yaxis_range=[0, 1])\n",
    "\t\tfig.update_traces(\n",
    "\t\t\thovertemplate=\"<br>\".join([\n",
    "                'Confidence - BLEU: %{customdata[4]}', \n",
    "\t\t\t\t\"Confidence - Inverse PPL: %{y}\",\n",
    "\t\t\t\t\"Variability - Inverse PPL: %{x}\",\n",
    "\t\t\t\t\"In: %{customdata[0]}\",\n",
    "\t\t\t\t\"Out: %{customdata[1]}\",\n",
    "                \"In Len: %{customdata[2]}\",\n",
    "                \"Out Len: %{customdata[3]}\", \n",
    "\t\t\t])\n",
    "\t\t)\n",
    "\telif plot_type == \"chia\":\n",
    "\t\tfig = px.scatter(df, x=\"Variability - CHIA\", y=\"Confidence - CHIA\", custom_data=['In abbv.', 'Out abbv.', 'In Len', 'Out Len'], color='Confidence - BLEU', range_color=[0,1])\n",
    "\t\tfig.update_layout(yaxis_range=[0, 1])\n",
    "\t\tfig.update_traces(\n",
    "\t\t\thovertemplate=\"<br>\".join([\n",
    "\t\t\t\t\"Variability - CHIA: %{x}\",\n",
    "\t\t\t\t\"Confidence - CHIA: %{y}\",\n",
    "\t\t\t\t\"In: %{customdata[0]}\",\n",
    "\t\t\t\t\"Out: %{customdata[1]}\",\n",
    "                \"In Len: %{customdata[2]}\",\n",
    "                \"Out Len: %{customdata[3]}\", \n",
    "\t\t\t])\n",
    "\t\t)\n",
    "\telif plot_type == \"bleu\":\n",
    "\t\tfig = px.scatter(df, x=\"Variability - BLEU\", y=\"Confidence - BLEU\", custom_data=['In abbv.', 'Out abbv.', 'In Len', 'Out Len'], color='Confidence - BLEU', range_color=[0,1])\n",
    "\t\tfig.update_layout(yaxis_range=[0, 1])\n",
    "\t\tfig.update_traces(\n",
    "\t\t\thovertemplate=\"<br>\".join([\n",
    "\t\t\t\t\"Variability - BLEU: %{x}\",\n",
    "\t\t\t\t\"Confidence - BLEU: %{y}\",\n",
    "\t\t\t\t\"In: %{customdata[0]}\",\n",
    "\t\t\t\t\"Out: %{customdata[1]}\",\n",
    "                \"In Len: %{customdata[2]}\",\n",
    "                \"Out Len: %{customdata[3]}\", \n",
    "\t\t\t])\n",
    "\t\t)\t\n",
    "\tfig.update_traces(marker=dict(size=3), selector=dict(mode='markers'))\n",
    "\tfig.update_layout(\n",
    "\t\tautosize=False,\n",
    "\t\twidth=800,\n",
    "\t\theight=900\n",
    "\t)\n",
    "\tfig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0386cacd-8d81-4d94-aa31-dcf8606f950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_TRUNCATE = 120\n",
    "\n",
    "mtrc2abv = {\"Inverse PPL\": \"inv_ppl\", \"Neg PPL\": \"neg_ppl\", \"CHIA\": \"chia\", \"BLEU\": \"bleu\"}\n",
    "crit2abv = {\"Easy to Learn\": \"easy_to_learn\", \"Ambiguous\": \"ambiguous\", \"Hard to Learn\": \"hard_to_learn\", \"Random\": \"random\"}\n",
    "create_fname = lambda m, cr, c_e: f\"{mtrc2abv[m]}_{crit2abv[cr]}_{c_e}.pickle\"\n",
    "outputs_path = lambda x: f\"../scores/{x}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "883ded4f-6ad1-45c3-823e-0609df0ac4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files in: ../scores/cogs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 5302/5302 [00:00<00:00, 8944.13it/s]\n",
      "  5%|â         | 119/2610 [00:00<00:01, 1498.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_idx: 2573\n",
      "113 113\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"cogs\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"CHIA\"\n",
    "CRITERIA = \"Easy to Learn\"\n",
    "CONVERGE_EPOCH = 10\n",
    "\n",
    "idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695afffb-e198-4d06-9ecf-5ad749509664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9d900-82eb-4167-bb69-acc1b3da5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeddcebe-c42a-478a-8a46-01403d42d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"cfq\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"Inverse PPL\"\n",
    "CRITERIA = \"Hard to Learn\"\n",
    "CONVERGE_EPOCH = 20\n",
    "MIN_EPOCH = 3\n",
    "\n",
    "MIN_EPOCHS = list(range(3,10))\n",
    "\n",
    "subset_dfs = []\n",
    "for MIN_EPOCH in MIN_EPOCHS:\n",
    "    idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE, min_epoch=MIN_EPOCH)\n",
    "    df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "    idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "    subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)\n",
    "    subset_dfs.append(subset_df)\n",
    "    print(\"appended\")\n",
    "    \n",
    "print(f\"subset_dfs length: {subset_dfs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8659c-655e-4ec7-86dc-a3df5199c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b04c3af-3a8c-46f9-9581-afe26d125313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9848393733185631\n",
      "0.974204779237221\n",
      "0.9622092103180883\n",
      "0.9510365564171546\n",
      "0.939167589808514\n",
      "0.9264757081816744\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    overlap = pd.merge(subset_dfs[0], subset_dfs[i], on=[\"In\", \"Out\"])\n",
    "    print(len(overlap) / len(subset_dfs[i-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3af7aee-2def-4240-a2c8-feb26193a6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Confidence - Inverse PPL</th>\n",
       "      <th>Variability - Inverse PPL</th>\n",
       "      <th>Confidence - CHIA</th>\n",
       "      <th>Variability - CHIA</th>\n",
       "      <th>Confidence - BLEU</th>\n",
       "      <th>Variability - BLEU</th>\n",
       "      <th>In Len</th>\n",
       "      <th>Out Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47824.534515</td>\n",
       "      <td>0.466942</td>\n",
       "      <td>0.042864</td>\n",
       "      <td>0.707840</td>\n",
       "      <td>0.015350</td>\n",
       "      <td>0.587209</td>\n",
       "      <td>0.030640</td>\n",
       "      <td>16.098338</td>\n",
       "      <td>32.820573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27611.626217</td>\n",
       "      <td>0.069945</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.047751</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.087382</td>\n",
       "      <td>0.018321</td>\n",
       "      <td>4.110672</td>\n",
       "      <td>9.770332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.047624</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.412916</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.200342</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23991.000000</td>\n",
       "      <td>0.428646</td>\n",
       "      <td>0.033463</td>\n",
       "      <td>0.680564</td>\n",
       "      <td>0.011709</td>\n",
       "      <td>0.527204</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47873.000000</td>\n",
       "      <td>0.483027</td>\n",
       "      <td>0.042338</td>\n",
       "      <td>0.716070</td>\n",
       "      <td>0.014897</td>\n",
       "      <td>0.592544</td>\n",
       "      <td>0.027109</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71702.000000</td>\n",
       "      <td>0.521511</td>\n",
       "      <td>0.051626</td>\n",
       "      <td>0.741028</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>0.650216</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95741.000000</td>\n",
       "      <td>0.553840</td>\n",
       "      <td>0.131577</td>\n",
       "      <td>0.842290</td>\n",
       "      <td>0.038702</td>\n",
       "      <td>0.883377</td>\n",
       "      <td>0.148065</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Index  Confidence - Inverse PPL  Variability - Inverse PPL  \\\n",
       "count  31595.000000              31595.000000               31595.000000   \n",
       "mean   47824.534515                  0.466942                   0.042864   \n",
       "std    27611.626217                  0.069945                   0.013842   \n",
       "min        9.000000                  0.047624                   0.000843   \n",
       "25%    23991.000000                  0.428646                   0.033463   \n",
       "50%    47873.000000                  0.483027                   0.042338   \n",
       "75%    71702.000000                  0.521511                   0.051626   \n",
       "max    95741.000000                  0.553840                   0.131577   \n",
       "\n",
       "       Confidence - CHIA  Variability - CHIA  Confidence - BLEU  \\\n",
       "count       31595.000000        31595.000000       31595.000000   \n",
       "mean            0.707840            0.015350           0.587209   \n",
       "std             0.047751            0.005124           0.087382   \n",
       "min             0.412916            0.001288           0.200342   \n",
       "25%             0.680564            0.011709           0.527204   \n",
       "50%             0.716070            0.014897           0.592544   \n",
       "75%             0.741028            0.018525           0.650216   \n",
       "max             0.842290            0.038702           0.883377   \n",
       "\n",
       "       Variability - BLEU        In Len       Out Len  \n",
       "count        31595.000000  31595.000000  31595.000000  \n",
       "mean             0.030640     16.098338     32.820573  \n",
       "std              0.018321      4.110672      9.770332  \n",
       "min              0.000081      4.000000     11.000000  \n",
       "25%              0.016868     13.000000     27.000000  \n",
       "50%              0.027109     16.000000     31.000000  \n",
       "75%              0.041016     19.000000     38.000000  \n",
       "max              0.148065     29.000000     95.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f36ef52-3caf-46a3-836b-979221196f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Confidence - Inverse PPL</th>\n",
       "      <th>Variability - Inverse PPL</th>\n",
       "      <th>Confidence - CHIA</th>\n",
       "      <th>Variability - CHIA</th>\n",
       "      <th>Confidence - BLEU</th>\n",
       "      <th>Variability - BLEU</th>\n",
       "      <th>In Len</th>\n",
       "      <th>Out Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "      <td>31595.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47719.256275</td>\n",
       "      <td>0.243603</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.574963</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.423512</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>15.854882</td>\n",
       "      <td>32.195790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27636.005096</td>\n",
       "      <td>0.048972</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.054798</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.092274</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>4.225663</td>\n",
       "      <td>9.700922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.228675</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.077110</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23799.500000</td>\n",
       "      <td>0.212468</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>0.542018</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.361978</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47705.000000</td>\n",
       "      <td>0.252956</td>\n",
       "      <td>0.013854</td>\n",
       "      <td>0.580059</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.424092</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71594.500000</td>\n",
       "      <td>0.283736</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>0.612036</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.487254</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95741.000000</td>\n",
       "      <td>0.309184</td>\n",
       "      <td>0.074025</td>\n",
       "      <td>0.769981</td>\n",
       "      <td>0.033170</td>\n",
       "      <td>0.760679</td>\n",
       "      <td>0.126684</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Index  Confidence - Inverse PPL  Variability - Inverse PPL  \\\n",
       "count  31595.000000              31595.000000               31595.000000   \n",
       "mean   47719.256275                  0.243603                   0.015071   \n",
       "std    27636.005096                  0.048972                   0.008006   \n",
       "min        9.000000                  0.014594                   0.000022   \n",
       "25%    23799.500000                  0.212468                   0.009292   \n",
       "50%    47705.000000                  0.252956                   0.013854   \n",
       "75%    71594.500000                  0.283736                   0.019455   \n",
       "max    95741.000000                  0.309184                   0.074025   \n",
       "\n",
       "       Confidence - CHIA  Variability - CHIA  Confidence - BLEU  \\\n",
       "count       31595.000000        31595.000000       31595.000000   \n",
       "mean            0.574963            0.007663           0.423512   \n",
       "std             0.054798            0.003739           0.092274   \n",
       "min             0.228675            0.000175           0.077110   \n",
       "25%             0.542018            0.004969           0.361978   \n",
       "50%             0.580059            0.007109           0.424092   \n",
       "75%             0.612036            0.009721           0.487254   \n",
       "max             0.769981            0.033170           0.760679   \n",
       "\n",
       "       Variability - BLEU        In Len       Out Len  \n",
       "count        31595.000000  31595.000000  31595.000000  \n",
       "mean             0.013594     15.854882     32.195790  \n",
       "std              0.012169      4.225663      9.700922  \n",
       "min              0.000003      4.000000     11.000000  \n",
       "25%              0.004866     13.000000     25.000000  \n",
       "50%              0.010194     16.000000     31.000000  \n",
       "75%              0.018661     19.000000     38.000000  \n",
       "max              0.126684     29.000000     95.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa05ac-b74a-4b7b-aee1-e85ad573b04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c92c9b-5732-4bad-a925-619c13113d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68bf404-d765-476d-adf5-8a061d867bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72b236-10ee-4298-a123-dce854744882",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"scan_length\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"CHIA\"\n",
    "CRITERIA = \"Easy to Learn\"\n",
    "CONVERGE_EPOCH = 30\n",
    "\n",
    "idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84eee1-dea9-4283-9d3a-aca5858b5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fecc0c5-917c-4bc7-82e8-fc9960a8facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5290f9-8645-4c19-ab8a-a4807b93f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"scan_jump\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"CHIA\"\n",
    "CRITERIA = \"Easy to Learn\"\n",
    "CONVERGE_EPOCH = 30\n",
    "\n",
    "idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db220853-5e76-4f14-a28d-ce15f987b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5761e02a-6200-4e0e-9aa7-0dcb4652c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139b1c8-6c44-48a2-aa6e-936c7a156a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0137f9-7d90-4afb-a054-de2cc56e0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"pcfg\"\n",
    "OUTPUTS_PATH = outputs_path(DATASET_NAME)\n",
    "METRIC = \"CHIA\"\n",
    "CRITERIA = \"Easy to Learn\"\n",
    "CONVERGE_EPOCH = 140\n",
    "\n",
    "idx_dict, i2s = get_scores(OUTPUTS_PATH, CONVERGE_EPOCH, STRING_TRUNCATE)\n",
    "df = calculate_statistics(CONVERGE_EPOCH, idx_dict, i2s)\n",
    "idx_fname = create_fname(METRIC, CRITERIA, CONVERGE_EPOCH)\n",
    "subset_df = choose_subset(df, METRIC, CRITERIA, DATASET_NAME, idx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b6c1b-9b5e-4cdf-b88c-d86b79dbf281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b342e-9e75-42d5-b608-656081535685",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bf9bfb-32c1-468e-9f15-60493c553ec8",
   "metadata": {},
   "source": [
    "subset_df_in = set(subset_df[\"In\"].tolist())\n",
    "subset_df_out = set(subset_df[\"Out\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553192c-6d24-4ad5-9b8f-6b39117d8bb1",
   "metadata": {},
   "source": [
    "subset_pkl = read_pickle(\"../scores/cogs/idx_to_sentences.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a7e7f-5c17-4ec5-8be5-8d01353590ef",
   "metadata": {},
   "source": [
    "subset_pkl_in = []\n",
    "subset_pkl_out = []\n",
    "\n",
    "for i, text in subset_pkl.items():\n",
    "    subset_pkl_in.append(text[\"in\"])\n",
    "    subset_pkl_out.append(text[\"out\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab763559-2449-410a-960b-d999ebc0e234",
   "metadata": {},
   "source": [
    "subset_pkl_in = set(subset_pkl_in)\n",
    "subset_pkl_out = set(subset_pkl_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edd506-124d-4657-ba1e-906fb731f680",
   "metadata": {},
   "source": [
    "subset_df_in - subset_pkl_in, len(subset_df_in), len(subset_pkl_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
